# NLP2021_project

# 1 задача
Для дальнейшей работы с данными провели разметку BIO-tagging с помощью stanza.
Далее сделали классификатор с помощью предобученной модели rubert-tiny.  https://huggingface.co/cointegrated/rubert-tiny

Эта моделька - дистильнутая версия  bert-base-multilingual-cased, поэтому весит мало и работает быстро. Размерность - 312.
При этом, по словам разработчика, она хорошо подходит длля задач классификации и NER

Классификатор был обучен на размечнных данных (предобработка не использовалась ввиду отсутствия ее необходимости для BERTа). Выставили следующие параметры:

- optimizer AdamW
- learning rate 5e-5
- 3 эпохи
- batch_size 8

Получили {'accuracy': 0.9201591736516807}
Связано скорее с тем, что мы использовали пустые значения как класс. Модель правильно определяет и наличие, и отсутсвие сущности

Эксперименты: проводились эксперименты с параметрами модели, но ничего фантастического из этого не вышло, результаты примерно такие же.


# 2 задача
В качестве лейблов используем сентименты (positive, negative etc).
Также создали классификатор с помощью предобученной модели rubert-tiny.
Также не использовалась предобработка и были выставлены те же параметры.

Получили {'accuracy': 0.9067818135636271}

Эксперименты проводились те же, так как классификатор тот же.

# 3 задача
Определить тональность каждого аспекта для отзыва в целом, зная оценки тональности для словосочетаний, относящихся к аспектам.
Бейзлайн: для каждого аспекта - ответ самая частая тональность.
Звучит логично, давайте подумаем, что еще можно придумать. Например, сразу брать в ответ тональность первого словосочетания. Вторая версия -  обозначить тональности за -1, +1 и 0, и посчитать сумму (score). Третья версия - то же, что вторая, но тональность первого словосочетания брать с весом два, рассчитывая, что в начале говорится наиболее важная информация, а потом детали.

Бейзлайн на трейне - 0.716

Первая версия - 0.657

Вторая версия - 0.776

Третья версия - 0.781

Затем мы заметили, что в категории WHOLE всегда что-то есть, даже если не было ни одного аспекта, с упоминанием чего-то из WHOLE. Добавили условие, что если ни одного WHOLE нету, то whole считается из всех аспектов.
Третья версия+ - 0.786
Затем мы заметили, что есть еще тональность ‘both’, попытались добавить условие, что если score попадает в самый частый диапазон для ‘both’, и число позитивных и негативных словосочетаний тоже самое частотное для такой штуки, то будем присваивать аспекту тональность both. В итоге где-то с both мы угадали, но чаще налажали с тем, что раньше определяли верно, точность снизилась - 0.768.

Лучше всего подходит третья версия.
